{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "##计算图（Graph）:搭建神经网络的计算过程，只搭建，不运算\n",
    "x=tf.constant([[1.0,2.0]])\n",
    "w=tf.constant([[3.0],[4.0]])\n",
    "y=tf.matmul(x,w)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.]]\n"
     ]
    }
   ],
   "source": [
    "##会话（Session）:执行计算图中的节点运算\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 两层简单神经网络（全连接）前向传播【喂一组数据】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= Tensor(\"MatMul_1:0\", shape=(1, 3), dtype=float32)\n",
      "y= Tensor(\"MatMul_2:0\", shape=(1, 1), dtype=float32)\n",
      "y is:\n",
      " [[3.0904665]]\n"
     ]
    }
   ],
   "source": [
    "##定义输入和参数\n",
    "x= tf.constant([[0.7,0.5]])\n",
    "w1= tf.Variable(tf.random_normal([2,3], stddev=1, seed=1))\n",
    "w2= tf.Variable(tf.random_normal([3,1], stddev=1, seed=1))\n",
    "\n",
    "##定义前向传播过程\n",
    "a=tf.matmul(x,w1)\n",
    "y=tf.matmul(a,w2)\n",
    "print(\"a=\",a)\n",
    "print(\"y=\",y)\n",
    "##用会话计算结果\n",
    "with tf.Session() as sess:\n",
    "    init_op= tf.global_variables_initializer()\n",
    "    sess.run(init_op) ##把网络的节点按照上面的参数进行设置初始参数\n",
    "    print(\"y is:\\n\", sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 两层简单神经网络（全连接）前向传播【喂一组数据，用placeholder占位】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= Tensor(\"MatMul_3:0\", shape=(1, 3), dtype=float32)\n",
      "y= Tensor(\"MatMul_4:0\", shape=(1, 1), dtype=float32)\n",
      "y is:\n",
      " [[3.0904665]]\n"
     ]
    }
   ],
   "source": [
    "##定义输入和参数\n",
    "\n",
    "##placeholder相当于输入的定义，但是现在未赋值\n",
    "x=tf.placeholder(tf.float32,shape=(1,2))\n",
    "w1= tf.Variable(tf.random_normal([2,3], stddev=1, seed=1))\n",
    "w2= tf.Variable(tf.random_normal([3,1], stddev=1, seed=1))\n",
    "\n",
    "##定义前向传播过程\n",
    "a=tf.matmul(x,w1)\n",
    "y=tf.matmul(a,w2)\n",
    "print(\"a=\",a)\n",
    "print(\"y=\",y)\n",
    "##用会话计算结果\n",
    "with tf.Session() as sess:\n",
    "    init_op= tf.global_variables_initializer()\n",
    "    sess.run(init_op) ##把网络的节点按照上面的参数进行设置初始参数\n",
    "    print(\"y is:\\n\", sess.run(y, feed_dict={x:[[0.7,0.5]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 两层简单神经网络（全连接）前向传播【喂多组数据，用placeholder占位】"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= Tensor(\"MatMul_5:0\", shape=(?, 3), dtype=float32)\n",
      "y= Tensor(\"MatMul_6:0\", shape=(?, 1), dtype=float32)\n",
      "y is:\n",
      " [[3.0904665]\n",
      " [1.2236414]\n",
      " [1.7270732]\n",
      " [2.2305048]]\n",
      "w1:\n",
      " [[-0.8113182   1.4845988   0.06532937]\n",
      " [-2.4427042   0.0992484   0.5912243 ]]\n",
      "w2=\n",
      " [[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]]\n"
     ]
    }
   ],
   "source": [
    "##定义输入和参数\n",
    "\n",
    "##placeholder相当于输入的定义，但是现在未赋值\n",
    "x=tf.placeholder(tf.float32,shape=(None,2))\n",
    "w1= tf.Variable(tf.random_normal([2,3], stddev=1, seed=1))\n",
    "w2= tf.Variable(tf.random_normal([3,1], stddev=1, seed=1))\n",
    "\n",
    "##定义前向传播过程\n",
    "a=tf.matmul(x,w1)\n",
    "y=tf.matmul(a,w2)\n",
    "print(\"a=\",a)\n",
    "print(\"y=\",y)\n",
    "##用会话计算结果\n",
    "with tf.Session() as sess:\n",
    "    init_op= tf.global_variables_initializer()\n",
    "    sess.run(init_op) ##把网络的节点按照上面的参数进行设置初始参数\n",
    "    print(\"y is:\\n\", sess.run(y, feed_dict={x:[[0.7,0.5],[0.2,0.3],[0.3,0.4],[0.4,0.5]]}))\n",
    "    print(\"w1:\\n\",sess.run(w1))\n",
    "    print(\"w2=\\n\",sess.run(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "反向传播，梯度优化，生成随机数据模拟二分类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[0.83494319 0.11482951]\n",
      " [0.66899751 0.46594987]\n",
      " [0.60181666 0.58838408]\n",
      " [0.31836656 0.20502072]\n",
      " [0.87043944 0.02679395]\n",
      " [0.41539811 0.43938369]\n",
      " [0.68635684 0.24833404]\n",
      " [0.97315228 0.68541849]\n",
      " [0.03081617 0.89479913]\n",
      " [0.24665715 0.28584862]\n",
      " [0.31375667 0.47718349]\n",
      " [0.56689254 0.77079148]\n",
      " [0.7321604  0.35828963]\n",
      " [0.15724842 0.94294584]\n",
      " [0.34933722 0.84634483]\n",
      " [0.50304053 0.81299619]\n",
      " [0.23869886 0.9895604 ]\n",
      " [0.4636501  0.32531094]\n",
      " [0.36510487 0.97365522]\n",
      " [0.73350238 0.83833013]\n",
      " [0.61810158 0.12580353]\n",
      " [0.59274817 0.18779828]\n",
      " [0.87150299 0.34679501]\n",
      " [0.25883219 0.50002932]\n",
      " [0.75690948 0.83429824]\n",
      " [0.29316649 0.05646578]\n",
      " [0.10409134 0.88235166]\n",
      " [0.06727785 0.57784761]\n",
      " [0.38492705 0.48384792]\n",
      " [0.69234428 0.19687348]\n",
      " [0.42783492 0.73416985]\n",
      " [0.09696069 0.04883936]]\n",
      "Y:\n",
      " [[1], [0], [0], [1], [1], [1], [1], [0], [1], [1], [1], [0], [0], [0], [0], [0], [0], [1], [0], [0], [1], [1], [0], [1], [0], [1], [1], [1], [1], [1], [0], [1]]\n",
      "w1:\n",
      " [[-0.8113182   1.4845988   0.06532937]\n",
      " [-2.4427042   0.0992484   0.5912243 ]]\n",
      "w2:\n",
      " [[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]]\n",
      "After 0 trian steps, loss on all data is 5.13118\n",
      "After 500 trian steps, loss on all data is 0.429111\n",
      "After 1000 trian steps, loss on all data is 0.409789\n",
      "After 1500 trian steps, loss on all data is 0.399923\n",
      "After 2000 trian steps, loss on all data is 0.394146\n",
      "After 2500 trian steps, loss on all data is 0.390597\n",
      "w1:\n",
      " [[-0.7000663   0.91363174  0.0895357 ]\n",
      " [-2.3402493  -0.14641264  0.58823055]]\n",
      "w2:\n",
      " [[-0.06024268]\n",
      " [ 0.91956186]\n",
      " [-0.06820709]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "BATCH_SIZE=8\n",
    "seed=23455\n",
    "\n",
    "##基于seed产生随机数据集\n",
    "rng=np.random.RandomState(seed)\n",
    "##表示X数据有32组，两个特征，分别表示重量和体积\n",
    "X=rng.rand(32,2)\n",
    "##y标签，基于X的特点产生y.两个特征和小于1则y=0，大于1，y=0\n",
    "Y= [[int(x0+x1 < 1) ] for x0,x1 in X]\n",
    "print(\"X:\\n\",X)\n",
    "print(\"Y:\\n\",Y)\n",
    "\n",
    "##1.定义神经网络输入，参数和输出【前向传播过程】\n",
    "x = tf.placeholder(tf.float32, shape=(None,2))\n",
    "y_ = tf.placeholder(tf.float32, shape=(None,1))\n",
    "\n",
    "w1=tf.Variable(tf.random_normal([2,3], stddev=1, seed=1))\n",
    "w2=tf.Variable(tf.random_normal([3,1], stddev=1, seed=1))\n",
    "\n",
    "a=tf.matmul(x,w1)\n",
    "y=tf.matmul(a,w2)\n",
    "\n",
    "##2.定义损失函数及传播方法\n",
    "loss= tf.reduce_mean(tf.square(y-y_))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "\n",
    "##3.生成会话，训练STEP\n",
    "with tf.Session() as sess:\n",
    "    init_op=tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    # 输出目前未经训练的参数权值\n",
    "    print(\"w1:\\n\",sess.run(w1))\n",
    "    print(\"w2:\\n\",sess.run(w2))\n",
    "    \n",
    "    # 训练模型\n",
    "    STEPS = 3000 ## 每一次喂入一个BATCH_SIZE，喂STEPS轮。一共有32组数据，遍历完需要4轮。一共3000轮，遍历完数据的次数是3000/4\n",
    "    for i in range(STEPS):\n",
    "        start = (i*BATCH_SIZE) % 32\n",
    "        end = start + BATCH_SIZE\n",
    "        sess.run(train_step, feed_dict= {x: X[start:end], y_: Y[start:end]})\n",
    "        if i % 500 == 0:\n",
    "            total_loss= sess.run(loss, feed_dict= {x: X, y_: Y})\n",
    "            print(\"After %d trian steps, loss on all data is %g\" % (i, total_loss))\n",
    "            \n",
    "    # 输出训练后的参数取值\n",
    "    print(\"w1:\\n\",sess.run(w1))\n",
    "    print(\"w2:\\n\",sess.run(w2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
